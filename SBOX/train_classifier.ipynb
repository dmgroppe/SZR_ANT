{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft of classification module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import ieeg_funcs as ief\n",
    "import dgFuncs as dg\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dgFuncs' from '/Users/davidgroppe/PycharmProjects/DG_LIBRARY/dgFuncs.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block for re-loading my libraries if I make updates\n",
    "import imp \n",
    "imp.reload(ief) \n",
    "imp.reload(dg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subs: ['CC', 'CJ', 'CO', 'CT', 'IB', 'JW', 'RB', 'TF']\n"
     ]
    }
   ],
   "source": [
    "# Import list of subjects to use\n",
    "path_dict=ief.get_path_dict()\n",
    "use_subs_df=pd.read_csv(os.path.join(path_dict['szr_ant_root'],'use_subs.txt'),header=None,na_filter=False)\n",
    "test_sub_list=['NA']\n",
    "train_subs_list=[]\n",
    "for sub in use_subs_df.iloc[:,0]:\n",
    "    if not sub in test_sub_list:\n",
    "        train_subs_list.append(sub)\n",
    "        \n",
    "print('Training subs: {}'.format(train_subs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ftrs=6\n",
      "n_wind=95615\n"
     ]
    }
   ],
   "source": [
    "# Figure out how much data there is to preallocate mem\n",
    "n_ftrs=0\n",
    "n_wind=0\n",
    "for sub in train_subs_list:\n",
    "    ftr_path=os.path.join(path_dict['ftrs_root'],'PWR',sub)\n",
    "    for f in os.listdir(ftr_path):\n",
    "        ftr_dict=np.load(os.path.join(ftr_path,f))\n",
    "        if n_ftrs==0:\n",
    "            n_ftrs=ftr_dict['db_pwr'].shape[0]\n",
    "        n_wind+=np.sum(ftr_dict['peri_ictal']>=0)\n",
    "print('n_ftrs=%d' % n_ftrs)\n",
    "print('n_wind=%d' % n_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_wind_sec', 'db_pwr', 'peri_ictal']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all data into a giant matrix\n",
    "ftrs=np.zeros((n_wind,n_ftrs))\n",
    "szr_class=np.zeros(n_wind)\n",
    "sub_id=np.zeros(n_wind)\n",
    "wind_ct=0\n",
    "sub_ct=0\n",
    "for sub in train_subs_list:\n",
    "    ftr_path=os.path.join(path_dict['ftrs_root'],'PWR',sub)\n",
    "    for f in os.listdir(ftr_path):\n",
    "        ftr_dict=np.load(os.path.join(ftr_path,f))\n",
    "        neo_wind=np.sum(ftr_dict['peri_ictal']>=0)\n",
    "        ftrs[wind_ct:wind_ct+neo_wind,:]=ftr_dict['db_pwr'][:,:neo_wind].T\n",
    "        szr_class[wind_ct:wind_ct+neo_wind]=ftr_dict['peri_ictal'][:neo_wind]\n",
    "        sub_id[wind_ct:wind_ct+neo_wind]=np.ones(neo_wind)*sub_ct\n",
    "        wind_ct+=neo_wind\n",
    "    sub_ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95615,)\n",
      "(95615, 6)\n"
     ]
    }
   ],
   "source": [
    "print(szr_class.shape)\n",
    "print(ftrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90170,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bro=szr_class[sub_id!=0]\n",
    "bro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to scale data\n",
    "#class_weight='balanced' and/o\n",
    "\n",
    "#gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.\n",
    "# Proper choice of C and gamma is critical to the SVMâ€™s performance. One is advised to \n",
    "# use sklearn.model_selection.GridSearchCV with C and gamma spaced exponentially far apart \n",
    "# to choose good values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOOCV on training data\n",
    "left_out_id=0\n",
    "C = 1.0  # SVM regularization parameter, the smaller it is, the stronger the regularization\n",
    "#rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(ftrs.T, szr_class)\n",
    "rbf_svc = svm.SVC(class_weight='balanced')\n",
    "# rbf_svc.fit? # could add sample weight to weight each subject equally\n",
    "rbf_svc.fit(ftrs[sub_id!=left_out_id,:], szr_class[sub_id!=left_out_id])\n",
    "#clf = svm.SVC()\n",
    "# >>> clf.fit(X, y)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bool=sub_id!=left_out_id\n",
    "valid_bool=sub_id==left_out_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_class_hat=rbf_svc.predict(ftrs)\n",
    "# training_class_hat=rbf_svc.predict(ftrs[sub_id!=left_out_id,:])\n",
    "training_class_hat=rbf_svc.predict(ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bool=sub_id!=left_out_id\n",
    "valid_bool=sub_id==left_out_id\n",
    "ictal_bool=szr_class==1\n",
    "preictal_bool=szr_class==0\n",
    "jive=training_class_hat==szr_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.975491\n",
      "Training sensitivity: 0.974138\n",
      "Training specificity: 0.975614\n"
     ]
    }
   ],
   "source": [
    "# Training Data Results\n",
    "train_acc=np.mean(jive[train_bool])\n",
    "print('Training accuracy: %f' % train_acc)\n",
    "use_ids=np.multiply(train_bool,ictal_bool)\n",
    "train_sens=np.mean(jive[use_ids])\n",
    "print('Training sensitivity: %f' % train_sens)\n",
    "use_ids=np.multiply(train_bool,preictal_bool)\n",
    "train_spec=np.mean(jive[use_ids])\n",
    "print('Training specificity: %f' % train_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.882645\n",
      "Validation sensitivity: 0.017949\n",
      "Validation specificity: 0.949357\n"
     ]
    }
   ],
   "source": [
    "# Validation Data Results\n",
    "valid_acc=np.mean(jive[valid_bool])\n",
    "print('Validation accuracy: %f' % valid_acc)\n",
    "use_ids=np.multiply(valid_bool,ictal_bool)\n",
    "valid_sens=np.mean(jive[use_ids])\n",
    "print('Validation sensitivity: %f' % valid_sens)\n",
    "use_ids=np.multiply(valid_bool,preictal_bool)\n",
    "valid_spec=np.mean(jive[use_ids])\n",
    "print('Validation specificity: %f' % valid_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.975491\n"
     ]
    }
   ],
   "source": [
    "train_acc=np.mean(training_class_hat==szr_class[train_bool])\n",
    "perionset_bool=szr_class==1\n",
    "use_ids=np.multiply(perionset_bool,train_bool)\n",
    "train_sens=np.mean(training_class_hat[np.multiply(perionset_bool,train_bool)]==szr_class[train_bool])\n",
    "print('Training accuracy: %f' % train_acc) #0.975892903833 acc all training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# out_fname=??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load validation data and calculate false positive rate, and peri-onset latency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVC()\n",
    "# >>> clf.fit(X, y)  \n",
    "# SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "#     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)\n",
    "# >>> clf.predict([[2., 2.]])\n",
    "# array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('classification_metrics.npz',\n",
    "         valid_sens=valid_sens,\n",
    "         valid_spec=valid_spec,\n",
    "         train_sens=train_sens,\n",
    "         train_spec=train_spec,\n",
    "         train_subs_list=train_subs_list,\n",
    "         left_out_id=left_out_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
